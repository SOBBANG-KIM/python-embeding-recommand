#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
update_embeddings.py
- ì‹ ê·œë©”ë‰´ ì¶”ê°€ ì‹œ ê¸°ì¡´ ë©”ë‰´ë“¤ì˜ ì„ë² ë”©ì„ ì¬ê³„ì‚°í•˜ì—¬ ë²¡í„° ê³µê°„ ì—…ë°ì´íŠ¸
- ìƒˆë¡œìš´ ë©”ë‰´ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë” ì •í™•í•œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥

ì‹¤í–‰ ì˜ˆì‹œ:
  python update_embeddings.py --index menus --batch-size 32
"""

import json
import argparse
from datetime import datetime, timezone
from typing import List, Dict, Any
from opensearchpy import OpenSearch, helpers
from sentence_transformers import SentenceTransformer
import numpy as np

# ì„¤ì •
INDEX_NAME = "menus"
ORDERS_FILE = "../json/order_menu.jsonl"

client = OpenSearch(
    hosts=[{"host": "localhost", "port": 9200}],
    http_auth=("admin", "admin"),
    use_ssl=False,
)

model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")


def now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def to_float(v, default=0.0) -> float:
    try:
        return float(v)
    except Exception:
        return float(default)


# ---- í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ìœ í‹¸ ----
def price_bucket(won: float) -> str:
    if won <= 5000: return "ì €ê°€"
    if won <= 12000: return "ì¤‘ê°€"
    return "ê³ ê°€"

def derive_attrs(name: str, desc: str, category: str) -> list[str]:
    txt = (name + " " + desc).lower()
    attrs = []

    # ë§›/ì¡°ë¦¬
    if any(k in txt for k in ["ë§¤ì½¤","ë§¤ìš´","ì–¼í°"]): attrs += ["ë§›: ë§¤ì›€"]
    if "ë‹¬ì½¤" in txt: attrs += ["ë§›: ë‹¬ì½¤"]
    if any(k in txt for k in ["ë‹´ë°±","ê¹”ë”"]): attrs += ["ë§›: ë‹´ë°±"]
    if any(k in txt for k in ["í† ë§ˆí† ","ë¡œì œ"]): attrs += ["ì†ŒìŠ¤: í† ë§ˆí† /ë¡œì œ"]
    if any(k in txt for k in ["í¬ë¦¼","ê¹Œë¥´ë³´"]): attrs += ["ì†ŒìŠ¤: í¬ë¦¼"]
    if any(k in txt for k in ["ë³¶ìŒ","êµ¬ì´","íŠ€ê¹€"]): attrs += ["ì¡°ë¦¬: ë³¶ìŒ/êµ¬ì´/íŠ€ê¹€"]
    if any(k in txt for k in ["êµ­","êµ­ë°¥","íƒ•","ì°Œê°œ"]): attrs += ["í˜•íƒœ: êµ­/íƒ•/ì°Œê°œ"]

    # ì¬ë£Œ/ì¢…ë¥˜
    if any(k in txt for k in ["í•´ë¬¼","í•´ì‚°ë¬¼","ìƒˆìš°","ì˜¤ì§•ì–´","ë¬¸ì–´","í™í•©"]): attrs += ["ì£¼ì¬ë£Œ: í•´ì‚°ë¬¼"]
    if any(k in txt for k in ["ì†Œê³ ê¸°","ì‡ ê³ ê¸°","ìš°","ì°¨ëŒ"]): attrs += ["ì£¼ì¬ë£Œ: ì†Œê³ ê¸°"]
    if any(k in txt for k in ["ë¼ì§€","ì‚¼ê²¹","ëª©ì‚´","ëˆ"]): attrs += ["ì£¼ì¬ë£Œ: ë¼ì§€ê³ ê¸°"]
    if any(k in txt for k in ["ë‹­","ì¹˜í‚¨","ê³„"]): attrs += ["ì£¼ì¬ë£Œ: ë‹­ê³ ê¸°"]
    if any(k in txt for k in ["ë©´","íŒŒìŠ¤íƒ€","ë¼ë©´","ìš°ë™"]): attrs += ["ì£¼ì‹: ë©´"]
    if any(k in txt for k in ["ë°¥","ë¹„ë¹”ë°¥","ë®ë°¥","ë³¶ìŒë°¥"]): attrs += ["ì£¼ì‹: ë°¥"]

    # ìŒë£Œ/ì£¼ë¥˜ ë³´ê°•
    if "ì½œë¼" in txt: attrs += ["ìŒë£Œ: íƒ„ì‚°", "ë§›: ë‹¬ì½¤", "ì°¨ê°€ì›€"]
    if any(k in txt for k in ["ì‚¬ì´ë‹¤","ìŠ¤í”„ë¼ì´íŠ¸"]): attrs += ["ìŒë£Œ: íƒ„ì‚°", "ì°¨ê°€ì›€"]
    if any(k in txt for k in ["ë§¥ì£¼","ì†Œì£¼","ì°¸ì´ìŠ¬","ì²­í•˜","ìœ„ìŠ¤í‚¤","ì™€ì¸"]): attrs += ["ì£¼ë¥˜"]

    # ì¹´í…Œê³ ë¦¬ ìì²´ë¥¼ íƒœê·¸ë¡œ
    if category:
        attrs += [f"ì¹´í…Œê³ ë¦¬: {category}"]

    return attrs

def build_embed_text(menu_name: str, description: str = "", category: str = "", price: float = 0) -> str:
    name = menu_name.strip()
    desc = description.strip()
    cat = category.strip()
    attrs = derive_attrs(name, desc, cat)
    attrs.append(f"ê°€ê²©ëŒ€: {price_bucket(price)}")
    # ìµœì¢… ë¬¸ì¥
    return ". ".join(filter(None, [name, desc] + attrs)) + "."


def get_all_menus_from_index(index_name: str) -> List[Dict[str, Any]]:
    """ì¸ë±ìŠ¤ì—ì„œ ëª¨ë“  ë©”ë‰´ ë°ì´í„° ì¡°íšŒ"""
    menus = []
    
    # Scroll APIë¡œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
    resp = client.search(
        index=index_name,
        body={
            "size": 1000,  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜
            "query": {"match_all": {}},
            "_source": ["menu_id", "menu_name", "category", "price", "description", 
                       "w_pop", "w_recency", "w_custom", "related_menus"]
        },
        scroll="5m"
    )
    
    scroll_id = resp["_scroll_id"]
    hits = resp["hits"]["hits"]
    
    while hits:
        for hit in hits:
            source = hit["_source"]
            source["_id"] = hit["_id"]  # ë¬¸ì„œ ID ì¶”ê°€
            menus.append(source)
        
        # ë‹¤ìŒ ë°°ì¹˜ ì¡°íšŒ
        resp = client.scroll(scroll_id=scroll_id, scroll="5m")
        scroll_id = resp["_scroll_id"]
        hits = resp["hits"]["hits"]
    
    # Scroll ì •ë¦¬
    client.clear_scroll(scroll_id=scroll_id)
    
    return menus


def update_embeddings_full_reindex(index_name: str, batch_size: int = 32):
    """ì „ì²´ ë©”ë‰´ì˜ ì„ë² ë”©ì„ ì¬ê³„ì‚°í•˜ì—¬ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
    print(f"ğŸ”„ ì „ì²´ ì„ë² ë”© ì¬ê³„ì‚° ì‹œì‘: {index_name}")
    
    # 1. ëª¨ë“  ë©”ë‰´ ë°ì´í„° ì¡°íšŒ
    menus = get_all_menus_from_index(index_name)
    print(f"ğŸ“Š ì´ {len(menus)}ê°œ ë©”ë‰´ ë°œê²¬")
    
    if not menus:
        print("âŒ ì—…ë°ì´íŠ¸í•  ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. ì„ë² ë”© í…ìŠ¤íŠ¸ ìƒì„±
    embed_texts = []
    for menu in menus:
        embed_text = build_embed_text(
            menu.get("menu_name", ""),
            menu.get("description", ""),
            menu.get("category", ""),
            to_float(menu.get("price", 0))
        )
        embed_texts.append(embed_text)
    
    # 3. ìƒˆë¡œìš´ ì„ë² ë”© ìƒì„±
    print(f"ğŸ§  {len(embed_texts)}ê°œ ë©”ë‰´ ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = model.encode(
        embed_texts, 
        batch_size=batch_size,
        convert_to_numpy=True, 
        normalize_embeddings=True, 
        show_progress_bar=True
    )
    
    # 4. ë²Œí¬ ì—…ë°ì´íŠ¸
    def gen_update_actions():
        for menu, embedding in zip(menus, embeddings):
            yield {
                "_index": index_name,
                "_id": menu["_id"],
                "_op_type": "update",
                "doc": {
                    "embedding": embedding.astype(float).tolist(),
                    "updated_at": now_iso()
                }
            }
    
    print("ğŸ“ ë²Œí¬ ì—…ë°ì´íŠ¸ ì¤‘...")
    success, failed = helpers.bulk(
        client, 
        gen_update_actions(), 
        chunk_size=1000, 
        request_timeout=120, 
        stats_only=True
    )
    
    print(f"âœ… ì„ë² ë”© ì—…ë°ì´íŠ¸ ì™„ë£Œ: ì„±ê³µ={success}, ì‹¤íŒ¨={failed}")


def update_embeddings_incremental(new_menus: List[Dict[str, Any]], index_name: str, batch_size: int = 32):
    """ìƒˆë¡œìš´ ë©”ë‰´ë“¤ë§Œ ì¶”ê°€í•˜ì—¬ ì„ë² ë”© ê³µê°„ í™•ì¥"""
    print(f"ğŸ†• ì¦ë¶„ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹œì‘: {len(new_menus)}ê°œ ì‹ ê·œë©”ë‰´")
    
    if not new_menus:
        print("âŒ ì¶”ê°€í•  ì‹ ê·œë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 1. ì„ë² ë”© í…ìŠ¤íŠ¸ ìƒì„±
    embed_texts = []
    for menu in new_menus:
        embed_text = build_embed_text(
            menu.get("menu_name", ""),
            menu.get("description", ""),
            menu.get("category", ""),
            to_float(menu.get("price", 0))
        )
        embed_texts.append(embed_text)
    
    # 2. ìƒˆë¡œìš´ ì„ë² ë”© ìƒì„±
    print(f"ğŸ§  {len(embed_texts)}ê°œ ì‹ ê·œë©”ë‰´ ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = model.encode(
        embed_texts, 
        batch_size=batch_size,
        convert_to_numpy=True, 
        normalize_embeddings=True, 
        show_progress_bar=True
    )
    
    # 3. ì‹ ê·œë©”ë‰´ ì¶”ê°€
    def gen_index_actions():
        for menu, embedding in zip(new_menus, embeddings):
            doc = {
                "menu_id": menu.get("menu_id"),
                "menu_name": menu.get("menu_name"),
                "category": menu.get("category"),
                "price": to_float(menu.get("price", 0)),
                "description": menu.get("description", ""),
                "created_at": now_iso(),
                "embedding": embedding.astype(float).tolist(),
                "related_menus": menu.get("related_menus", []),
                "w_pop": to_float(menu.get("w_pop", 1.0)),
                "w_recency": to_float(menu.get("w_recency", 1.0)),
                "w_custom": to_float(menu.get("w_custom", 1.0)),
                "attributes": derive_attrs(
                    menu.get("menu_name", ""),
                    menu.get("description", ""),
                    menu.get("category", "")
                )
            }
            
            yield {
                "_index": index_name,
                "_id": menu.get("menu_id"),
                "_op_type": "index",
                "_source": doc
            }
    
    print("ğŸ“ ì‹ ê·œë©”ë‰´ ì¸ë±ì‹± ì¤‘...")
    success, failed = helpers.bulk(
        client, 
        gen_index_actions(), 
        chunk_size=1000, 
        request_timeout=120, 
        stats_only=True
    )
    
    print(f"âœ… ì‹ ê·œë©”ë‰´ ì¶”ê°€ ì™„ë£Œ: ì„±ê³µ={success}, ì‹¤íŒ¨={failed}")


def update_embeddings_with_related_menus(index_name: str, batch_size: int = 32, include_embedding_similarity: bool = True):
    """ì—°ê´€ë©”ë‰´ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì„ë² ë”© ì—…ë°ì´íŠ¸ (ì„ë² ë”© ìœ ì‚¬ë„ í¬í•¨)"""
    print(f"ğŸ”— ì—°ê´€ë©”ë‰´ ì •ë³´ í¬í•¨ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹œì‘")
    
    # 1. ì£¼ë¬¸ ë¡œê·¸ ì½ê¸°
    orders = []
    with open(ORDERS_FILE, "r", encoding="utf-8") as f:
        for line in f:
            orders.append(json.loads(line))
    
    # 2. ê³µë™ì£¼ë¬¸ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    from collections import defaultdict
    import itertools
    
    co_matrix = defaultdict(lambda: defaultdict(int))
    menu_counts = defaultdict(int)
    
    for order in orders:
        menus = order["menus"]
        for menu in menus:
            menu_counts[menu] += 1
        for a, b in itertools.combinations(sorted(menus), 2):
            co_matrix[a][b] += 1
            co_matrix[b][a] += 1
    
    # 3. ëª¨ë“  ë©”ë‰´ ì¡°íšŒ
    menus = get_all_menus_from_index(index_name)
    print(f"ğŸ“Š ì´ {len(menus)}ê°œ ë©”ë‰´ ë°œê²¬")
    
    # 4. ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ì„ë² ë”© ìƒì„±
    if include_embedding_similarity:
        print("ğŸ§  ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
        menu_embeddings = {}
        
        for menu in menus:
            embed_text = build_embed_text(
                menu.get("menu_name", ""),
                menu.get("description", ""),
                menu.get("category", ""),
                to_float(menu.get("price", 0))
            )
            embedding = model.encode(embed_text)
            menu_embeddings[menu["_id"]] = {
                "embedding": embedding,
                "menu_name": menu.get("menu_name", ""),
                "category": menu.get("category", "")
            }
    
    # 5. ì—°ê´€ë©”ë‰´ ì •ë³´ ì—…ë°ì´íŠ¸
    def gen_update_actions():
        for menu in menus:
            menu_name = menu.get("menu_name", "")
            menu_id = menu["_id"]
            related_list = []
            
            # ê³µë™ì£¼ë¬¸ ê¸°ë°˜ ì—°ê´€ë©”ë‰´
            if menu_name in co_matrix:
                for other, count in co_matrix[menu_name].items():
                    score = count / menu_counts[menu_name]
                    related_list.append({
                        "menu_name": other,
                        "co_occurrence_score": round(score, 3),
                        "similarity_type": "co_occurrence"
                    })
            
            # ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ì—°ê´€ë©”ë‰´ (ê³µë™ì£¼ë¬¸ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°)
            if include_embedding_similarity and menu_id in menu_embeddings:
                current_embedding = menu_embeddings[menu_id]["embedding"]
                current_category = menu_embeddings[menu_id]["category"]
                
                # ê°™ì€ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ìœ ì‚¬í•œ ë©”ë‰´ ì°¾ê¸°
                similar_menus = []
                for other_id, other_data in menu_embeddings.items():
                    if other_id == menu_id:
                        continue
                    
                    # ê°™ì€ ì¹´í…Œê³ ë¦¬ ìš°ì„ , ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë„ í—ˆìš©
                    category_bonus = 1.5 if other_data["category"] == current_category else 1.0
                    
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = np.dot(current_embedding, other_data["embedding"]) / (
                        np.linalg.norm(current_embedding) * np.linalg.norm(other_data["embedding"])
                    )
                    
                    # ì¹´í…Œê³ ë¦¬ ë³´ë„ˆìŠ¤ ì ìš©
                    adjusted_similarity = similarity * category_bonus
                    
                    if adjusted_similarity > 0.3:  # ì„ê³„ê°’
                        similar_menus.append({
                            "menu_name": other_data["menu_name"],
                            "embedding_similarity": round(adjusted_similarity, 3),
                            "category": other_data["category"]
                        })
                
                # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 5ê°œ ì„ íƒ
                similar_menus.sort(key=lambda x: x["embedding_similarity"], reverse=True)
                
                for similar_menu in similar_menus[:5]:
                    # ê³µë™ì£¼ë¬¸ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì„ë² ë”© ìœ ì‚¬ë„ ì¶”ê°€
                    existing_co_occurrence = any(
                        item["menu_name"] == similar_menu["menu_name"] 
                        for item in related_list
                    )
                    
                    if not existing_co_occurrence:
                        related_list.append({
                            "menu_name": similar_menu["menu_name"],
                            "embedding_similarity": similar_menu["embedding_similarity"],
                            "similarity_type": "embedding",
                            "category": similar_menu["category"]
                        })
            
            # ìµœì¢… ì—°ê´€ë©”ë‰´ ë¦¬ìŠ¤íŠ¸ (ê³µë™ì£¼ë¬¸ ìš°ì„ , ì„ë² ë”© ìœ ì‚¬ë„ ë³´ì™„)
            final_related_list = []
            
            # ê³µë™ì£¼ë¬¸ ê¸°ë°˜ ë¨¼ì € ì¶”ê°€
            co_occurrence_items = [item for item in related_list if item.get("similarity_type") == "co_occurrence"]
            final_related_list.extend(co_occurrence_items)
            
            # ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ê°€ (ê³µë™ì£¼ë¬¸ì´ ë¶€ì¡±í•œ ê²½ìš°)
            embedding_items = [item for item in related_list if item.get("similarity_type") == "embedding"]
            final_related_list.extend(embedding_items[:max(0, 5 - len(co_occurrence_items))])
            
            print(f"ğŸ“‹ {menu_name}: ê³µë™ì£¼ë¬¸ {len(co_occurrence_items)}ê°œ, ì„ë² ë”© ìœ ì‚¬ë„ {len(embedding_items)}ê°œ")
            
            yield {
                "_index": index_name,
                "_id": menu_id,
                "_op_type": "update",
                "doc": {
                    "related_menus": final_related_list,
                    "updated_at": now_iso()
                }
            }
    
    print("ğŸ“ ì—°ê´€ë©”ë‰´ ì •ë³´ ì—…ë°ì´íŠ¸ ì¤‘...")
    success, failed = helpers.bulk(
        client, 
        gen_update_actions(), 
        chunk_size=1000, 
        request_timeout=120, 
        stats_only=True
    )
    
    print(f"âœ… ì—°ê´€ë©”ë‰´ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ì„±ê³µ={success}, ì‹¤íŒ¨={failed}")


def main():
    parser = argparse.ArgumentParser(description="ë©”ë‰´ ì„ë² ë”© ì—…ë°ì´íŠ¸ ë„êµ¬")
    parser.add_argument("--index", default=INDEX_NAME, help="ì¸ë±ìŠ¤ ì´ë¦„")
    parser.add_argument("--mode", choices=["full", "incremental", "related"], 
                       default="full", help="ì—…ë°ì´íŠ¸ ëª¨ë“œ")
    parser.add_argument("--batch-size", type=int, default=32, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--new-menus-file", help="ì‹ ê·œë©”ë‰´ JSON íŒŒì¼ (incremental ëª¨ë“œìš©)")
    
    args = parser.parse_args()
    
    if args.mode == "full":
        update_embeddings_full_reindex(args.index, args.batch_size)
    elif args.mode == "incremental":
        if not args.new_menus_file:
            print("âŒ incremental ëª¨ë“œì—ì„œëŠ” --new-menus-fileì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        with open(args.new_menus_file, "r", encoding="utf-8") as f:
            new_menus = json.load(f)
        update_embeddings_incremental(new_menus, args.index, args.batch_size)
    elif args.mode == "related":
        update_embeddings_with_related_menus(args.index, args.batch_size)


if __name__ == "__main__":
    main()
