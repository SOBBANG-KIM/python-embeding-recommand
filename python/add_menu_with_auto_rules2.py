import json
import itertools
from collections import defaultdict
from datetime import datetime, timezone
from opensearchpy import OpenSearch
from sentence_transformers import SentenceTransformer
import numpy as np

INDEX_NAME = "menus"
ORDERS_FILE = "../json/order_menu.jsonl"

client = OpenSearch(
    hosts=[{"host": "localhost", "port": 9200}],
    http_auth=("admin", "admin"),
    use_ssl=False,
)

model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")


def now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def to_float(v, default=0.0) -> float:
    try:
        return float(v)
    except Exception:
        return float(default)


# ---- í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ìœ í‹¸ ----
def price_bucket(won: float) -> str:
    if won <= 5000: return "ì €ê°€"
    if won <= 12000: return "ì¤‘ê°€"
    return "ê³ ê°€"

def derive_attrs(name: str, desc: str, category: str) -> list[str]:
    txt = (name + " " + desc).lower()
    attrs = []

    # ë§›/ì¡°ë¦¬
    if any(k in txt for k in ["ë§¤ì½¤","ë§¤ìš´","ì–¼í°"]): attrs += ["ë§›: ë§¤ì›€"]
    if "ë‹¬ì½¤" in txt: attrs += ["ë§›: ë‹¬ì½¤"]
    if any(k in txt for k in ["ë‹´ë°±","ê¹”ë”"]): attrs += ["ë§›: ë‹´ë°±"]
    if any(k in txt for k in ["í† ë§ˆí† ","ë¡œì œ"]): attrs += ["ì†ŒìŠ¤: í† ë§ˆí† /ë¡œì œ"]
    if any(k in txt for k in ["í¬ë¦¼","ê¹Œë¥´ë³´"]): attrs += ["ì†ŒìŠ¤: í¬ë¦¼"]
    if any(k in txt for k in ["ë³¶ìŒ","êµ¬ì´","íŠ€ê¹€"]): attrs += ["ì¡°ë¦¬: ë³¶ìŒ/êµ¬ì´/íŠ€ê¹€"]
    if any(k in txt for k in ["êµ­","êµ­ë°¥","íƒ•","ì°Œê°œ"]): attrs += ["í˜•íƒœ: êµ­/íƒ•/ì°Œê°œ"]

    # ì¬ë£Œ/ì¢…ë¥˜
    if any(k in txt for k in ["í•´ë¬¼","í•´ì‚°ë¬¼","ìƒˆìš°","ì˜¤ì§•ì–´","ë¬¸ì–´","í™í•©"]): attrs += ["ì£¼ì¬ë£Œ: í•´ì‚°ë¬¼"]
    if any(k in txt for k in ["ì†Œê³ ê¸°","ì‡ ê³ ê¸°","ìš°","ì°¨ëŒ"]): attrs += ["ì£¼ì¬ë£Œ: ì†Œê³ ê¸°"]
    if any(k in txt for k in ["ë¼ì§€","ì‚¼ê²¹","ëª©ì‚´","ëˆ"]): attrs += ["ì£¼ì¬ë£Œ: ë¼ì§€ê³ ê¸°"]
    if any(k in txt for k in ["ë‹­","ì¹˜í‚¨","ê³„"]): attrs += ["ì£¼ì¬ë£Œ: ë‹­ê³ ê¸°"]
    if any(k in txt for k in ["ë©´","íŒŒìŠ¤íƒ€","ë¼ë©´","ìš°ë™"]): attrs += ["ì£¼ì‹: ë©´"]
    if any(k in txt for k in ["ë°¥","ë¹„ë¹”ë°¥","ë®ë°¥","ë³¶ìŒë°¥"]): attrs += ["ì£¼ì‹: ë°¥"]

    # ìŒë£Œ/ì£¼ë¥˜ ë³´ê°•
    if "ì½œë¼" in txt: attrs += ["ìŒë£Œ: íƒ„ì‚°", "ë§›: ë‹¬ì½¤", "ì°¨ê°€ì›€"]
    if any(k in txt for k in ["ì‚¬ì´ë‹¤","ìŠ¤í”„ë¼ì´íŠ¸"]): attrs += ["ìŒë£Œ: íƒ„ì‚°", "ì°¨ê°€ì›€"]
    if any(k in txt for k in ["ë§¥ì£¼","ì†Œì£¼","ì°¸ì´ìŠ¬","ì²­í•˜","ìœ„ìŠ¤í‚¤","ì™€ì¸"]): attrs += ["ì£¼ë¥˜"]

    # ì¹´í…Œê³ ë¦¬ ìì²´ë¥¼ íƒœê·¸ë¡œ
    if category:
        attrs += [f"ì¹´í…Œê³ ë¦¬: {category}"]

    return attrs

def build_embed_text(menu_name: str, description: str = "", category: str = "", price: float = 0) -> str:
    name = menu_name.strip()
    desc = description.strip()
    cat = category.strip()
    attrs = derive_attrs(name, desc, cat)
    attrs.append(f"ê°€ê²©ëŒ€: {price_bucket(price)}")
    # ìµœì¢… ë¬¸ì¥
    return ". ".join(filter(None, [name, desc] + attrs)) + "."


def ensure_index_with_weights(client: OpenSearch, index_name: str, dim: int = 384):
    """ê°€ì¤‘ì¹˜ í•„ë“œê°€ í¬í•¨ëœ ì¸ë±ìŠ¤ ìƒì„±"""
    if client.indices.exists(index=index_name):
        return
    
    mapping = {
        "settings": {"index": {"knn": True}},
        "mappings": {
            "properties": {
                "menu_id": {"type": "keyword"},
                "menu_name": {"type": "text"},
                "category": {"type": "keyword"},
                "price": {"type": "float"},
                "description": {"type": "text"},
                "created_at": {"type": "date"},
                "embedding": {
                    "type": "knn_vector",
                    "dimension": dim,
                    "method": {
                        "name": "hnsw",
                        "engine": "lucene",
                        "space_type": "cosinesimil",
                        "parameters": {"m": 24, "ef_construction": 128},
                    },
                },
                "related_menus": {
                    "type": "nested",
                    "properties": {
                        "menu_name": {"type": "keyword"},
                        "co_occurrence_score": {"type": "float"}
                    }
                },
                # ê°€ì¤‘ì¹˜ í•„ë“œë“¤
                "w_pop": {"type": "float"},
                "w_recency": {"type": "float"},
                "w_custom": {"type": "float"},
                "attributes": {"type": "keyword"},  # ìë™ ì¶”ì¶œëœ ì†ì„±ë“¤
            }
        },
    }
    client.indices.create(index=index_name, body=mapping)
    print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_name}")


def build_cooccurrence_matrix(orders):
    co_matrix = defaultdict(lambda: defaultdict(int))
    menu_counts = defaultdict(int)

    for order in orders:
        menus = order["menus"]
        for menu in menus:
            menu_counts[menu] += 1
        for a, b in itertools.combinations(sorted(menus), 2):
            co_matrix[a][b] += 1
            co_matrix[b][a] += 1

    return co_matrix, menu_counts


def add_new_menu_with_auto_rules(
    menu_name: str, 
    description: str = "", 
    category: str = "", 
    price: float = 0.0,
    menu_id: str = None,
    w_pop: float = 1.0,
    w_recency: float = 1.0,
    w_custom: float = 1.0,
    index_name=INDEX_NAME
):
    # âœ… 1. ì£¼ë¬¸ ë¡œê·¸ ì½ê¸°
    orders = []
    with open(ORDERS_FILE, "r", encoding="utf-8") as f:
        for line in f:
            orders.append(json.loads(line))

    co_matrix, menu_counts = build_cooccurrence_matrix(orders)

    # âœ… 2. ì¸ë±ìŠ¤ í™•ì¸/ìƒì„±
    ensure_index_with_weights(client, index_name)

    # âœ… 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì„ë² ë”©
    embed_text = build_embed_text(menu_name, description, category, price)
    embedding = model.encode(embed_text).tolist()
    
    # âœ… 4. ì†ì„± ì¶”ì¶œ
    attributes = derive_attrs(menu_name, description, category)

    # âœ… 5. ê³µë™ì£¼ë¬¸ ë°ì´í„° ìˆìœ¼ë©´ ì§ì ‘ ë°˜ì˜
    related_list = []
    if menu_name in co_matrix:
        for other, count in co_matrix[menu_name].items():
            score = count / menu_counts[menu_name]
            related_list.append({
                "menu_name": other,
                "co_occurrence_score": round(score, 3)
            })

    # âœ… 6. ê³µë™ì£¼ë¬¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ â†’ ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ ë©”ë‰´ ì°¾ê¸°
    if not related_list:
        print("ğŸ“Œ ê³µë™ì£¼ë¬¸ ë°ì´í„° ì—†ìŒ â†’ ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ì—°ê´€ë©”ë‰´ ìƒì„±")
        
        # ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ë©”ë‰´ë“¤ ì°¾ê¸°
        resp = client.search(
            index=index_name,
            body={
                "size": 10,  # ë” ë§ì€ í›„ë³´ ê²€ìƒ‰
                "query": {
                    "knn": {
                        "embedding": {
                            "vector": embedding,
                            "k": 10
                        }
                    }
                },
                "_source": ["menu_name", "category", "embedding"]
            }
        )
        
        if resp["hits"]["hits"]:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            current_embedding = np.array(embedding)
            similar_menus = []
            
            for hit in resp["hits"]["hits"]:
                other_menu = hit["_source"]
                other_embedding = np.array(other_menu["embedding"])
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = np.dot(current_embedding, other_embedding) / (
                    np.linalg.norm(current_embedding) * np.linalg.norm(other_embedding)
                )
                
                # ì¹´í…Œê³ ë¦¬ ë³´ë„ˆìŠ¤ (ê°™ì€ ì¹´í…Œê³ ë¦¬ ìš°ì„ )
                category_bonus = 1.5 if other_menu.get("category") == category else 1.0
                adjusted_similarity = similarity * category_bonus
                
                if adjusted_similarity > 0.3:  # ì„ê³„ê°’
                    similar_menus.append({
                        "menu_name": other_menu["menu_name"],
                        "embedding_similarity": round(adjusted_similarity, 3),
                        "similarity_type": "embedding",
                        "category": other_menu.get("category", "")
                    })
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 5ê°œ ì„ íƒ
            similar_menus.sort(key=lambda x: x["embedding_similarity"], reverse=True)
            related_list = similar_menus[:5]
            
            print(f"ğŸ” ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ì—°ê´€ë©”ë‰´ {len(related_list)}ê°œ ìƒì„±")
            for item in related_list:
                print(f"   - {item['menu_name']} (ìœ ì‚¬ë„: {item['embedding_similarity']})")

    # âœ… 7. OpenSearchì— ì €ì¥ (ê°€ì¤‘ì¹˜ í•„ë“œ í¬í•¨)
    doc = {
        "menu_id": menu_id or f"menu_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "menu_name": menu_name,
        "category": category,
        "price": price,
        "description": description,
        "created_at": now_iso(),
        "embedding": embedding,
        "related_menus": related_list,
        # ê°€ì¤‘ì¹˜ í•„ë“œë“¤
        "w_pop": w_pop,
        "w_recency": w_recency,
        "w_custom": w_custom,
        "attributes": attributes
    }

    resp = client.index(index=index_name, body=doc)
    print(f"âœ… ì‹ ë©”ë‰´ ë“±ë¡ ì™„ë£Œ: {menu_name}, id={resp['_id']}")
    print(f"â¡ï¸ ê°€ê²©ëŒ€: {price_bucket(price)}")
    print(f"â¡ï¸ ì†ì„±: {attributes}")
    print(f"â¡ï¸ ì—°ê´€ë©”ë‰´: {len(related_list)}ê°œ")
    return resp['_id']


# ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ê¸°ë³¸ ì˜ˆì‹œ
    # add_new_menu_with_auto_rules("ë¡œì œ íŒŒìŠ¤íƒ€")
    
    # ìƒì„¸ ì •ë³´ í¬í•¨ ì˜ˆì‹œ
    add_new_menu_with_auto_rules(
        menu_name="í¬ë¦¼ ì¹´ë¥´ë³´ë‚˜ë¼",
        description="ë¶€ë“œëŸ¬ìš´ í¬ë¦¼ì†ŒìŠ¤ì™€ ë² ì´ì»¨ì´ ì–´ìš°ëŸ¬ì§„ íŒŒìŠ¤íƒ€",
        category="íŒŒìŠ¤íƒ€",
        price=15000,
        w_pop=1.2,  # ì¸ê¸°ë„ ë†’ìŒ
        w_recency=1.0,
        w_custom=1.1
    )
